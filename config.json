{
  "default": {
    "wikievents": "True",
    "adam_epsilon": 1e-08,
    "cache_dir": "",
    "config_name": "",
    "data_dir": "",
    "debug": "",
    "do_lower_case": "False",
    "do_predict": "True",
    "do_train": "False",
    "eval_batch_size": 1,
    "fp16": "",
    "fp16_opt_level": "O1",
    "gradient_accumulation_steps": 1,
    "labels": "None",
    "learning_rate": 5e-05,
    "max_grad_norm": 1.0,
    "max_seq_length_src": 300,
    "max_seq_length_tgt": 150,
    "model_name_or_path": "bert-base-uncased",
    "model_type": "bert",
    "n_gpu": 1,
    "n_tpu_cores": 0,
    "num_train_epochs": 50,
    "output_dir": "/outputs",
    "overwrite_cache": "True",
    "seed": 1,
    "server_ip": "",
    "server_port": "",
    "thresh": 1,
    "tokenizer_name": "",
    "train_batch_size": 1,
    "warmup_steps": 0,
    "weight_decay": 0.0,
    "pretrained_path": "s3://experiment-logging/storage/GTT/test-gtt.2991a1d48c1743d4b6f223b74d9ba640/models/epoch=43-step=57199.ckpt"
  }
}